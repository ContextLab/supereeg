{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Simulate data\n\n\nIn this example, we load in a single subject example, remove electrodes that exceed\na kurtosis threshold (in place), load a model, and predict activity at all\nmodel locations.\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Code source: Andrew Heusser & Lucy Owen\n# License: MIT\n\nimport superEEG as se\nimport scipy\nimport numpy as np\nfrom superEEG._helpers.stats import r2z, z2r, get_expanded_corrmat_fit, get_expanded_corrmat_predict, rbf\nfrom numpy import inf\nfrom scipy.stats import zscore\n\n\n\nR = scipy.linalg.toeplitz(np.linspace(0, 1, 3)[::-1])\nmodel_locs = np.array([[0, 0, 0], [0, 0, 1], [0, 0, 2]])\nsubject_locs = np.array([[0, 0, 3], [0, 0, 4]])\nfull_locs = np.vstack([model_locs, subject_locs])\nweights = rbf(full_locs, model_locs, width=2)\nnum_fit, denom_fit = get_expanded_corrmat_fit(R, weights)\nnum_predict, denom_predict = get_expanded_corrmat_predict(R, weights)\nfit = np.divide(num_fit, denom_fit)\npredict = np.divide(num_predict, denom_predict)\nprint fit, predict\nfit[:3, :3] = 0\nprint fit\nassert fit == predict\n\n#\n# # n_samples\n# n_samples = 1000\n#\n# # load example model to get locations\n# model = se.load('example_model')\n#\n# # get the locations\n# locs = model.locs\n#\n# # create a fake model\n# full_model = se.Model(data=scipy.linalg.toeplitz(np.linspace(0,1,len(locs))[::-1]), locs=locs)\n#\n# # create a random multivariate distribution\n# rand_dist = np.random.multivariate_normal(np.zeros(len(locs)), np.eye(len(locs)), size=n_samples)\n#\n# # multiply by the model to create the synthetic full brain activity\n# bo = se.Brain(data=np.dot(rand_dist, scipy.linalg.cholesky(full_model.data)), locs=locs)\n#\n# # indices: subset of 10 from full location for the synthetic subject data and the rest for the synthetic model\n# locs_inds = range(0,len(locs))\n# sub_inds = locs_inds[0::5]\n# model_inds = list(set(locs_inds)-set(sub_inds))\n#\n#\n# # create a brain object that is a subsample of the full data - this is the synthetic subject data\n# bo_sub = se.Brain(data=bo.data.iloc[:, sub_inds], locs=bo.locs.iloc[sub_inds, :])\n#\n# # create a new model that is a subsample of the full model - this is the synthetic model\n# model = se.Model(data=full_model.data.as_matrix()[:, model_inds][model_inds], locs=full_model.locs.iloc[model_inds, :])\n#\n# temp = r2z(model.data)\n# temp[temp == inf] = 0\n# model.data = temp\n# reconstructed = model.predict(bo_sub)\n# expected = zscore(bo.data.iloc[:, model_inds])\n# import seaborn as sb\n# sb.jointplot(reconstructed.data.iloc[:,0], expected[:, 0])\n#\n# ### below works:\n#\n# bo_sub = se.Brain(data=bo.data.iloc[:, range(1,len(locs))], locs=bo.locs.iloc[range(1,len(locs)), :])\n#\n# def reconstruct_activity(bo, K):\n#     \"\"\"\n#     \"\"\"\n#     s = K.shape[0]-bo.locs.shape[0]\n#     Kba = K[:s,s:]\n#     Kaa = K[s:,s:]\n#     Y = zscore(bo.get_data())\n#     return np.squeeze(np.dot(np.dot(Kba, np.linalg.pinv(Kaa)), Y.T).T)\n#\n#\n# reconstructed_activity = reconstruct_activity(bo_sub, model.data.as_matrix())\n#\n# import seaborn as sb\n# sb.jointplot(reconstructed_activity, bo.data[0])"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.10", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}