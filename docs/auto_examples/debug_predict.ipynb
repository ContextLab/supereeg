{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# debug predict\n\n\nThis example shows debugging process for predict.  Delete before pip push.\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Code source: Lucy Owen & Andrew Heusser\n# License: MIT\n\n\nimport supereeg as se\nimport sys\nimport numpy as np\nfrom supereeg.helpers import _corr_column, _count_overlapping\ntry:\n    from itertools import zip_longest\nexcept:\n    from itertools import izip_longest as zip_longest\n\nfrom scipy.stats import zscore\n#\n# def round_it(locs, places):\n#     \"\"\"\n#     Rounding function\n#\n#     Parameters\n#     ----------\n#     locs : float\n#         Number be rounded\n#\n#     places : int\n#         Number of places to round\n#\n#     Returns\n#     ----------\n#     result : float\n#         Rounded number\n#\n#\n#     \"\"\"\n#     return np.round(locs, decimals=places)\n#\n# def get_rows(all_locations, subj_locations):\n#     \"\"\"\n#         This function indexes a subject's electrode locations in the full array of electrode locations\n#\n#         Parameters\n#         ----------\n#         all_locations : ndarray\n#             Full array of electrode locations\n#\n#         subj_locations : ndarray\n#             Array of subject's electrode locations\n#\n#         Returns\n#         ----------\n#         results : list\n#             Indexs for subject electrodes in the full array of electrodes\n#\n#         \"\"\"\n#     if subj_locations.ndim == 1:\n#         subj_locations = subj_locations.reshape(1, 3)\n#     inds = np.full([1, subj_locations.shape[0]], np.nan)\n#     for i in range(subj_locations.shape[0]):\n#         possible_locations = np.ones([all_locations.shape[0], 1])\n#         try:\n#             for c in range(all_locations.shape[1]):\n#                 possible_locations[all_locations[:, c] != subj_locations[i, c], :] = 0\n#             inds[0, i] = np.where(possible_locations == 1)[0][0]\n#         except:\n#             pass\n#     inds = inds[~np.isnan(inds)]\n#     return [int(x) for x in inds]\n#\n# def known_unknown(fullarray, knownarray, subarray=None, electrode=None):\n#     \"\"\"\n#         This finds the indices for known and unknown electrodes in the full array of electrode locations\n#\n#         Parameters\n#         ----------\n#         fullarray : ndarray\n#             Full array of electrode locations - All electrodes that pass the kurtosis test\n#\n#         knownarray : ndarray\n#             Subset of known electrode locations  - Subject's electrode locations that pass the kurtosis test (in the leave one out case, this is also has the specified location missing)\n#\n#         subarray : ndarray\n#             Subject's electrode locations (all)\n#\n#         electrode : str\n#             Index of electrode in subarray to remove (in the leave one out case)\n#\n#         Returns\n#         ----------\n#         known_inds : list\n#             List of known indices\n#\n#         unknown_inds : list\n#             List of unknown indices\n#\n#         \"\"\"\n#     ## where known electrodes are located in full matrix\n#     known_inds = get_rows(round_it(fullarray, 3), round_it(knownarray, 3))\n#     ## where the rest of the electrodes are located\n#     unknown_inds = list(set(range(np.shape(fullarray)[0])) - set(known_inds))\n#     if not electrode is None:\n#         ## where the removed electrode is located in full matrix\n#         rm_full_ind = get_rows(round_it(fullarray, 3), round_it(subarray[int(electrode)], 3))\n#         ## where the removed electrode is located in the unknown index subset\n#         rm_unknown_ind = np.where(np.array(unknown_inds) == np.array(rm_full_ind))[0].tolist()\n#         return known_inds, unknown_inds, rm_unknown_ind\n#     else:\n#         return known_inds, unknown_inds\n#\n#\n# def chunker(iterable, n, fillvalue=None):\n#     #\"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"\n#     args = [iter(iterable)] * n\n#     return zip_longest(fillvalue=fillvalue, *args)\n#\n# def time_by_file_index_bo(bo, ave_data, known_inds, unknown_inds):\n#     \"\"\"\n#     Session dependent function that calculates that finds either the timeseries or the correlation of the predicted and actual timeseries for a given location chunked by 25000 timepoints\n#\n#     Parameters\n#     ----------\n#     fname : Data matrix (npz file)\n#         The data to be analyzed.\n#         Filename containing fields:\n#             Y - time series\n#             R - electrode locations\n#             fname_labels - session number\n#             sample_rate - sampling rate\n#\n#     ave_data: ndarray\n#         Average correlation matrix\n#\n#     known_inds: list\n#         Indices for known electrodes in average matrix\n#\n#     unknown_inds: list\n#         Indices for unknown electrodes in average matrix\n#\n#     electrode_ind: int\n#         Index for estimated location in average matrix (location in unknown_inds)\n#\n#     k_flat_removed: list\n#         Indices of good channels (pass kurtosis test) in Y\n#\n#     electrode: int\n#         Index of held out location in known_inds\n#\n#     time_series: boolean\n#         True: output is predicted and actual timeseries\n#         False: output is predicted and actual correlation\n#\n#     Returns\n#     ----------\n#     results : pandas dataframe\n#         If timeseries input is:\n#         True: output is predicted and actual timeseries\n#         False: output is predicted and actual correlation\n#\n#\n#     \"\"\"\n#     file_inds = np.unique(np.atleast_2d(bo.sessions.values))\n#     Kaa = np.float32(ave_data[known_inds, :][:, known_inds])\n#     Kaa_inv = np.linalg.pinv(Kaa)\n#     Kba = np.float32(ave_data[unknown_inds, :][:, known_inds])\n#     results = []\n#     for i in file_inds:\n#         if np.shape(np.atleast_2d(bo.sessions.values))[1] == 1:\n#             fname_labels = np.atleast_2d(bo.sessions.values).T\n#         else:\n#             fname_labels = np.atleast_2d(bo.sessions.values)\n#         next_inds = np.where(fname_labels == i)[1]\n#         ### this code should incorporate the average voltage of the known (subject) electrodes and the average for the unknown (the other subjects)\n#         block_results = []\n#         next = np.zeros((bo.get_data().shape[0], ave_data.shape[0]))\n#         ### right now, this doesn't use an overlap in time, but this needs to be addressed when I see edge effects\n#         for each in chunker(next_inds, 1000):\n#\n#             next[:, unknown_inds] = np.squeeze(np.dot(np.dot(Kba, Kaa_inv),\n#                                                zscore(np.float32(\n#                                                    bo.get_data().values[filter(lambda v: v is not None, each), :])).T).T)\n#             next[:, known_inds] = np.squeeze(zscore(np.float32(bo.get_data().values[filter(lambda v: v is not None, each), :])))\n#             if block_results==[]:\n#                 block_results = next\n#             else:\n#                 block_results = np.vstack((block_results, next))\n#         if results==[]:\n#             results = block_results\n#         else:\n#             results = np.vstack((block_results, results))\n#\n#         return results\n\n#\n# # simulate 100 locations\n# locs = se.simulate_locations(n_elecs=100, random_seed=True)\n#\n# # simulate brain object\n# bo = se.simulate_bo(n_samples=1000, sample_rate=100, cov='random', locs=locs, noise=0, random_seed=True)\n#\n# # sample 10 locations, and get indices\n# sub_locs = locs.sample(90, replace=False, random_state=123).sort_values(['x', 'y', 'z']).index.values.tolist()\n#\n# # index brain object to get sample patient\n# bo_sample = bo[: ,sub_locs]\n#\n# # plot sample patient locations\n# bo_sample.plot_locs()\n#\n# # plot sample patient data\n# bo_sample.plot_data()\n#\n# Model = se.Model(data=bo, locs=locs)\n#\n# R = Model.get_locs().values\n#\n# R_K_subj = bo_sample.get_locs().values\n#\n# known_inds, unknown_inds = known_unknown(R, R_K_subj, R_K_subj)\n#\n#\n#\n# recon_data = time_by_file_index_bo(bo_sample, Model.get_model(z_transform=False), known_inds, unknown_inds)\n#\n# bo_r = se.Brain(data=recon_data, locs = R, sample_rate=bo.sample_rate, sessions=bo.sessions.values)\n#\n#\n# corrs_1 = _corr_column(bo.get_data().values, bo_r.get_data().values)\n#\n# print('correlations with timeseries recon  = ' + str(corrs_1[unknown_inds].mean()))\n#\n#\n# bo_s = Model.predict(bo_sample, nearest_neighbor=False)\n#\n# recon_labels = np.where(np.array(bo_s.label) != 'observed')\n#\n# corrs = _corr_column(bo.get_data().values, bo_s.get_data().values)\n#\n# print('correlations with predict function = ' + str(corrs[recon_labels].mean()))\n#\n# assert np.allclose(corrs, corrs_1)\n\n\n########## debug case 1 - null set ##################\n\n# set random seed to default and noise to 0\nrandom_seed = np.random.seed(123)\nnoise = 0\n\n# locs\nlocs = se.simulate_locations(n_elecs=100, set_random_seed=random_seed)\n\n# create model locs from 75 locations\nmo_locs = locs.sample(75, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create covariance matrix from random seed\nc = se.create_cov(cov='random', n_elecs=100)\n\n# pull out model from covariance matrix\ndata = c[:, mo_locs.index][mo_locs.index, :]\n\n# create model from subsetted covariance matrix and locations\nmodel = se.Model(data=data, locs=mo_locs, n_subs=1)\n\n# create brain object from the remaining locations - first find remaining 25 locations\nsub_locs = locs[~locs.index.isin(mo_locs.index)]\n\n# create a brain object with all gray locations\nbo = se.simulate_bo(n_samples=1000, sample_rate=100, locs=locs, noise=noise, random_seed=random_seed)\n\n# parse brain object to create synthetic patient data\ndata = bo.data.iloc[:, sub_locs.index]\n\n# put data and locations together in new sample brain object\nbo_sample = se.Brain(data=data.values, locs=sub_locs, sample_rate=100)\n\n# predict activity at all unknown locations\nrecon = model.predict(bo_sample, nearest_neighbor=False)\n\n# get reconstructed indices\nrecon_labels = np.where(np.array(recon.label) != 'observed')\n\n# actual = bo.data.iloc[:, unknown_ind]\nactual_data = bo.get_zscore_data()[:, recon_labels[0]]\n\nrecon_data = recon[:, recon_labels[0]].get_data().values\ncorr_vals = _corr_column(actual_data, recon_data)\n\nprint('case 1 (null set) correlation = ' +str(corr_vals.mean()))\n\n\n\n\n########## debug case 2 - subset ##################\n\n# set random seed to default and noise to 0\nrandom_seed = np.random.seed(123)\nnoise = 0\n\n# locs\nlocs = se.simulate_locations(n_elecs=100, set_random_seed=random_seed)\n\n# create model locs from 50 locations\nmo_locs = locs.sample(100, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create covariance matrix from random seed\nc = se.create_cov(cov='random', n_elecs=100)\n\n# pull out model from covariance matrix\ndata = c[:, mo_locs.index][mo_locs.index, :]\n\n# create model from subsetted covariance matrix and locations\nmodel = se.Model(data=data, locs=mo_locs, n_subs=1)\n\n# create brain object from subset of model locations\nsub_locs = mo_locs.sample(25, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create a brain object with all gray locations\nbo = se.simulate_bo(n_samples=1000, sample_rate=100, locs=mo_locs, noise=noise, random_seed=random_seed)\n\n# parse brain object to create synthetic patient data\ndata = bo.data.iloc[:, sub_locs.index]\n\n# put data and locations together in new sample brain object\nbo_sample = se.Brain(data=data.values, locs=sub_locs, sample_rate=100)\n\n# predict activity at all unknown locations\nrecon = model.predict(bo_sample, nearest_neighbor=False)\n\n# get reconstructed indices\nrecon_labels = np.where(np.array(recon.label) != 'observed')\n\n# actual = bo.data.iloc[:, unknown_ind]\nactual_data = bo.get_zscore_data()[:, recon_labels[0]]\n\nrecon_data = recon[:, recon_labels[0]].get_data().values\ncorr_vals = _corr_column(actual_data, recon_data)\n\nprint('case 2 (subset of model) correlation = ' +str(corr_vals.mean()))\n\n########## debug case 3 - overlapping set ##################\n\n# set random seed to default and noise to 0\nrandom_seed = np.random.seed(123)\nnoise = 0\n\n# locs\nlocs = se.simulate_locations(n_elecs=100, set_random_seed=random_seed)\n\n# create model locs from 75 locations\nmo_locs = locs.sample(75, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create covariance matrix from random seed\nc = se.create_cov(cov='random', n_elecs=100)\n\n# pull out model from covariance matrix\ndata = c[:, mo_locs.index][mo_locs.index, :]\n\n# create model from subsetted covariance matrix and locations\nmodel = se.Model(data=data, locs=mo_locs, n_subs=1)\n\n# create brain object from all the locations - first find remaining 25 location\nsub_locs = locs[~locs.index.isin(mo_locs.index)]\n\n# then add 25 locations subsetted from model locations\nsub_locs = sub_locs.append(mo_locs.sample(25, random_state=random_seed).sort_values(['x', 'y', 'z']))\n\n# then subsample 25 from those locations to get some overlapping\nsub_locs.sample(25, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create a brain object with all gray locations\nbo = se.simulate_bo(n_samples=1000, sample_rate=100, locs=locs, noise=noise, random_seed=random_seed)\n\n# parse brain object to create synthetic patient data\ndata = bo.data.iloc[:, sub_locs.index]\n\n# put data and locations together in new sample brain object\nbo_sample = se.Brain(data=data.values, locs=sub_locs, sample_rate=100)\n\n# predict activity at all unknown locations\nrecon = model.predict(bo_sample, nearest_neighbor=False)\n\n# get reconstructed indices\nrecon_labels = np.where(np.array(recon.label) != 'observed')\n\n# actual = bo.data.iloc[:, unknown_ind]\nactual_data = bo.get_zscore_data()[:, recon_labels[0]]\n\nrecon_data = recon[:, recon_labels[0]].get_data().values\ncorr_vals = _corr_column(actual_data, recon_data)\n\nprint('case 3 (some overlap of model) correlation = ' +str(corr_vals.mean()))\n\n########## debug case 4 - model subset of brain object ##################\n\n# set random seed to default and noise to 0\nrandom_seed = np.random.seed(123)\nnoise = 0\n\n# locs\nlocs = se.simulate_locations(n_elecs=100, set_random_seed=random_seed)\n\n# create brain locs from 75 locations\nbo_locs = locs.sample(75, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create model locs from 50 locations\nmo_locs = bo_locs.sample(50, random_state=random_seed).sort_values(['x', 'y', 'z'])\n\n# create covariance matrix from random seed\nc = se.create_cov(cov='random', n_elecs=100)\n\n# pull out model from covariance matrix\ndata = c[:, mo_locs.index][mo_locs.index, :]\n\n# create model from subsetted covariance matrix and locations\nmodel = se.Model(data=data, locs=mo_locs, n_subs=1)\n\n\n# create a brain object with all gray locations\nbo = se.simulate_bo(n_samples=1000, sample_rate=100, locs=locs, noise=noise, random_seed=random_seed)\n\n# parse brain object to create synthetic patient data\ndata = bo.data.iloc[:, bo_locs.index]\n\n# put data and locations together in new sample brain object\nbo_sample = se.Brain(data=data.values, locs=bo_locs, sample_rate=100)\n\n# predict activity at all unknown locations\nrecon = model.predict(bo_sample, nearest_neighbor=False)\n\n# get reconstructed indices - since model is entirely a subset of brain object,\n# there should be no reconstructed locations\nrecon_labels = np.where(np.array(recon.label) != 'observed')\n\n# actual = bo.data.iloc[:, unknown_ind]\nactual_data = bo_sample.get_zscore_data()\n\nrecon_data = recon.get_data().values\ncorr_vals = _corr_column(actual_data, recon_data)\n\nprint('case 4 (model subset of brain locs) correlation = ' +str(corr_vals.mean()))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.10", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}
